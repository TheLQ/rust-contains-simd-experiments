// #![feature(portable_simd)]
// #![feature(slice_as_chunks)]
use std::arch::x86_64::{
    __m256i, _mm256_cmpeq_epi32, _mm256_cmpeq_epi64, _mm256_movemask_epi8, _mm256_or_si256,
};
use std::hint::black_box;
use std::io::Write;
use std::ptr;
// use std::simd::Simd;
use std::slice;
use std::{io, mem};

#[derive(Clone, PartialEq, Eq)]
struct VPoint {
    x: usize,
    y: i64,
}

// impl VPoint {
//     fn x(&self) -> i32 {
//         self.x
//     }

//     fn y(&self) -> i32 {
//         self.y
//     }
// }

// struct VArea {
//     start: VPoint,
//     end: VPoint
// }

// impl VArea {
//     fn between(&self, target: VPoint) -> bool {
//         target.x() >= self.start.x()
//             && target.x() <= self.end.x()
//             && target.y() >= self.start.y()
//             && target.y() <= self.end.y()
//         // (self.start.x()..self.end.x()).contains(&target.x()) &&
//         // (self.start.y()..self.end.y()).contains(&target.y())
//     }
// }

// #[inline(never)]
// fn never(start: i32, end: i32, middle: i32) -> bool {
//     let area = VArea {
//         start: VPoint { x: start, y: start + 99 },
//         end: VPoint { x: end, y: end + 99 }
//     };
//     area.between(VPoint {x: middle, y: middle + 99})
// }

// #[inline(never)]
// fn check_contains<T: std::cmp::PartialEq>(needle: T) -> bool {
//     let raw: &[T] = unsafe {
//         slice::from_raw_parts(ptr::without_provenance(55555), hint::black_box(5000))};
//     raw.contains(&needle)
// }

fn check_slice_contains_std<T: std::cmp::PartialEq>(input: &[T], needle: T) -> bool {
    input.contains(&needle)
}

#[inline(never)]
fn check_slice_contains_fast(arr: &[VPoint], needle: VPoint) -> bool {
    // Make our LANE_COUNT 4x the normal lane count (aiming for 128 bit vectors).
    // The compiler will nicely unroll it.
    const LANE_COUNT: usize = 4 * (128 / (size_of::<VPoint>() * 8));
    // SIMD
    let mut chunks = arr.chunks_exact(LANE_COUNT);
    for chunk in &mut chunks {
        if chunk.iter().fold(false, |acc, x| acc | (*x == needle)) {
            return true;
        }
    }
    // false
    // Scalar remainder
    chunks.remainder().iter().any(|x| *x == needle)
}

// #[target_feature(enable = "avx2")]
// fn check_slice_contains_fast_u64(arr: &[u64], needle_raw: u64) -> bool {
//     // const LANES: usize = 8;
//     const LANES: usize = 4 * (128 / (size_of::<u64>() * 8));
//     type MySimd = Simd<u64, LANES>;
//
//     let mut needle_array: [u64; LANES] = unsafe { mem::zeroed() };
//     needle_array.fill(needle_raw);
//     let needle = MySimd::from_array(needle_array);
//
//     let (pre, simd, post) = arr.as_simd();
//     let simd: &[MySimd] = simd;
//
//     // println!("test");
//     simd.iter().any(|c| *c == needle)
// }
//
// #[target_feature(enable = "avx2")]
// unsafe fn check_slice_contains_fast_u64_m256(arr: &[u64], needle_raw: u64) -> bool {
//     const LANES: usize = 4;
//     let mut needle_array: [u64; LANES] = unsafe { mem::zeroed() };
//     needle_array.fill(needle_raw);
//
//     // let needle = MySimd::from_array(needle_array);
//     let needle = __m256i::from(Simd::from_array(needle_array));
//
//     let (pre, register, post) = arr.as_simd::<LANES>();
//     let (superchunk, after) = register.as_chunks::<4>();
//     for chunk in superchunk {
//         // compare, with true=0xFF.. false=0x0
//         // let r1 = __m256i::from(chunk[0]);
//         // let r2 = __m256i::from(chunk[1]);
//         // let r3 = __m256i::from(chunk[2]);
//         // let r4 = __m256i::from(chunk[3]);
//         // let processed = chunk.map(|v| {
//         //     let m = __m256i::from(chunk[3]);
//         //     _mm256_cmpeq_epi64(m, needle)
//         // });
//         // OR results, we want to know if any matched
//         // let o1 = _mm256_or_si256(processed[0], processed[1]);
//         // let o2 = _mm256_or_si256(processed[2], processed[3]);
//
//         // let c0 = _mm256_cmpeq_epi64(__m256i::from(chunk[0]), needle);
//         // let c1 = _mm256_cmpeq_epi64(__m256i::from(chunk[1]), needle);
//         // let c2 = _mm256_cmpeq_epi64(__m256i::from(chunk[2]), needle);
//         // let c3 = _mm256_cmpeq_epi64(__m256i::from(chunk[3]), needle);
//         let c0 = _mm256_cmpeq_epi64(__m256i::from(chunk[0]), needle);
//         let c1 = _mm256_cmpeq_epi64(__m256i::from(chunk[1]), needle);
//         let c2 = _mm256_cmpeq_epi64(__m256i::from(chunk[2]), needle);
//         let c3 = _mm256_cmpeq_epi64(__m256i::from(chunk[3]), needle);
//
//         let o0 = _mm256_or_si256(c0, c1);
//         let o1 = _mm256_or_si256(c2, c3);
//         let o_final = _mm256_or_si256(o0, o1);
//
//         // reduce by grabbing arbitrary MSB, if all false this reduces to decimal 0
//         let any = _mm256_movemask_epi8(o_final);
//         if any != 0 {
//             return true;
//         }
//
//         // for register in chunk {
//         //     let m = __m256i::from(*register);
//         //     let comp = _mm256_cmpeq_epi64(m, needle);
//         //     let reduced = _mm256_movemask_epi8(comp);
//         //     if reduced > 0 {
//         //         return true;
//         //     }
//         // }
//     }
//     false
//     // println!("test");
//     // simd.iter().any(|c| {
//     //     let val: __m256i = c.into();
//     //     val == needle
//     // })
// }

// #[target_feature(enable = "avx2")]
#[inline(never)]
fn test_vec(input: &[u64]) -> bool {
    unsafe {
        match 3 {
            // 1 => check_slice_contains_fast_u64_m256(input, black_box(77)),
            // 2 => check_slice_contains_fast_u64(input, black_box(77)),
            3 => check_slice_contains_std(input, black_box(77)),
            _ => unimplemented!(),
        }
    }
}

fn main() {
    let input = vec![black_box(5u64); 9999];
    unsafe { println!("res {}", test_vec(&input)) }
}

#[cfg(test)]
mod test {
    use crate::{check_slice_contains_fast_u64, check_slice_contains_fast_u64_m256};

    const MULTIPLER: usize = 8;
    const DATA_CHUNK_SIZE: usize = 16;
    const SPOILER_MULTTIPLER: usize = MULTIPLER - 2;
    const DATA_SIZE: usize = MULTIPLER * DATA_CHUNK_SIZE;

    fn data() -> Vec<u64> {
        let mut data = Vec::new();
        for cur in 0..MULTIPLER {
            for _ in 0..(DATA_CHUNK_SIZE - 1) {
                data.push(55);
            }
            data.push(88);
            // data.push(55);
        }
        assert_eq!(data.len(), DATA_SIZE);
        data
    }

    #[test]
    fn sanity_simd_m256() {
        let data = data();
        // assert!(data.contains(&88));
        unsafe {
            assert!(check_slice_contains_fast_u64_m256(&data, 88));
            assert!(!check_slice_contains_fast_u64_m256(&data, 66));
        }
    }

    #[test]
    fn sanity_simd_portable() {
        let data = data();
        // assert!(data.contains(&88));
        assert!(check_slice_contains_fast_u64(&data, 88));
        assert!(!check_slice_contains_fast_u64(&data, 66));
    }
}
